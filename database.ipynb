{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducible experimental protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python packages\n",
    "\n",
    "- pyannote.audio\n",
    "- pyannote.core\n",
    "- pyannote.database\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AMI`: TODO TODO TODO\n",
    "- `ldc2019e31`: [Second DIHARD Challenge Development Data](https://coml.lscp.ens.fr/dihard/)\n",
    "- `ldc2019e32`: [Second DIHARD Challenge Evaluation Data](https://coml.lscp.ens.fr/dihard/)\n",
    "- `musan`: [A corpus of MUsic, Speech, And Noise](https://www.openslr.org/17/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where AMI has been downloaded\n",
    "ami = ''\n",
    "\n",
    "# where ldc2019e31 dataset has been downloaded\n",
    "ldc2019e31 = '/vol/corpora1/data/ldc/ldc2019e31/LDC2019E31_Second_DIHARD_Challenge_Development_Data'\n",
    "\n",
    "# where ldc2019e32 dataset has been downloaded \n",
    "ldc2019e32 = '/vol/corpora1/data/ldc/ldc2019e32/LDC2019E32_Second_DIHARD_Challenge_Evaluation_Data_V1.1'\n",
    "\n",
    "# where MUSAN has been downloaded from https://www.openslr.org/17/\n",
    "musan = '/vol/corpora4/musan'\n",
    "\n",
    "# where github.com/hbredin/DomainAdversarialVoiceActivityDetection has been cloned\n",
    "ROOT = '/vol/work1/bredin/jsalt/DomainAdversarialVoiceActivityDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'database' sub-directory that is meant to store audio and reference files\n",
    "!mkdir -p {ROOT}/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "from pyannote.core import Timeline\n",
    "from pyannote.core import Annotation\n",
    "from typing import TextIO\n",
    "\n",
    "def write_rttm(file: TextIO, reference: Annotation):\n",
    "    \"\"\"Write reference annotation to \"rttm\" file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : file object\n",
    "    reference : `pyannote.core.Annotation`\n",
    "        Reference annotation\n",
    "    \"\"\"\n",
    "\n",
    "    for s, t, l in reference.itertracks(yield_label=True):\n",
    "        line = (\n",
    "            f'SPEAKER {reference.uri} 1 {s.start:.3f} {s.duration:.3f} '\n",
    "            f'<NA> <NA> {l} <NA> <NA>\\n'\n",
    "        )\n",
    "        file.write(line)\n",
    "\n",
    "def write_uem(file: TextIO, uem: Timeline):\n",
    "    \"\"\"Write evaluation map to \"uem\" file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : file object\n",
    "    uem : `pyannote.core.Timeline`\n",
    "        Evaluation timeline\n",
    "    \"\"\"\n",
    "\n",
    "    for s in uem:\n",
    "        line = f'{uem.uri} 1 {s.start:.3f} {s.end:.3f}\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIHARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, development and evaluation subsets share the same names: `DH_0001` to `DH_0192` exist in both subsets.  \n",
    "To avoid any confusion in `pyannote.database`, we create symbolic links so we can distinguish `dev/DH_0001` from `tst/DH_0001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln --symbolic {ldc2019e31}/data/single_channel/flac {ROOT}/database/dev\n",
    "!ln --symbolic {ldc2019e32}/data/single_channel/flac {ROOT}/database/tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# load list of test files (and their domain)\n",
    "tst = read_csv(f'{ldc2019e32}/docs/sources.tbl', \n",
    "               delim_whitespace=True,\n",
    "               names=['uri', 'language', 'domain', 'source'],\n",
    "               index_col='uri').filter(like='DH', axis=0)\n",
    "\n",
    "# load list of development files (and their domain)\n",
    "dev = read_csv(f'{ldc2019e31}/docs/sources.tbl', \n",
    "               delim_whitespace=True,\n",
    "               names=['uri', 'language', 'domain', 'source'], \n",
    "               index_col='uri').filter(like='DH', axis=0)\n",
    "\n",
    "# obtain list of domains\n",
    "domains = sorted(dev.domain.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create four files per (domain, subset) pair:\n",
    "- `{domain}.{subset}.txt` contains list of files\n",
    "- `{domain}.{subset.rttm` contains manual annotation\n",
    "- `{domain}.{subset}.uem` contains unpartitioned evaluation map (uem)\n",
    "- `{domain}.domain.{subset}.txt` contains file-to-domain mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.database.util import load_rttm\n",
    "from pyannote.database.util import load_uem\n",
    "from pyannote.audio.features.utils import get_audio_duration\n",
    "from pyannote.core import Segment\n",
    "\n",
    "# split ldc2019e31 into training set (two third) and developement set (one third)\n",
    "\n",
    "# for each domain in ldc2019e31\n",
    "for domain, files in dev.groupby('domain'):\n",
    "    \n",
    "    # load unpartitioned evaluation map (uem)\n",
    "    uems = load_uem(f'{ldc2019e31}/data/single_channel/uem/{domain}.uem')\n",
    "    \n",
    "    # create four files per (domain, subset) pair\n",
    "    # {domain}.{subset}.txt contains list of files\n",
    "    # {domain}.{subset}.rttm contains manual annotation\n",
    "    # {domain}.{subset}.uem contains unpartitioned evaluation map (uem)\n",
    "    # {domain}.domain.{subset}.txt contains file-to-domain mapping\n",
    "    with open(f'{ROOT}/database/{domain}.dev.txt', 'w') as uris_dev, \\\n",
    "         open(f'{ROOT}/database/{domain}.trn.txt', 'w') as uris_trn, \\\n",
    "         open(f'{ROOT}/database/{domain}.dev.rttm', 'w') as rttm_dev, \\\n",
    "         open(f'{ROOT}/database/{domain}.trn.rttm', 'w') as rttm_trn, \\\n",
    "         open(f'{ROOT}/database/{domain}.dev.uem', 'w') as uem_dev, \\\n",
    "         open(f'{ROOT}/database/{domain}.trn.uem', 'w') as uem_trn, \\\n",
    "         open(f'{ROOT}/database/{domain}.domain.dev.txt', 'w') as domain_dev, \\\n",
    "         open(f'{ROOT}/database/{domain}.domain.trn.txt', 'w') as domain_trn:\n",
    "        \n",
    "        # for each file in current domain\n",
    "        for i, (uri, file) in enumerate(files.iterrows()):\n",
    "            \n",
    "            duration = get_audio_duration({'audio': f'{ROOT}/database/dev/{uri}.flac'})\n",
    "            # ugly hack to avoid rounding errors: this has the effect of not considering \n",
    "            # the last millisecond of each file\n",
    "            duration -= 0.001\n",
    "            support = Segment(0, duration)\n",
    "            \n",
    "            # i = 0 ==> dev\n",
    "            # i = 1 ==> trn\n",
    "            # i = 2 ==> trn\n",
    "            # i = 3 ==> dev\n",
    "            # i = 4 ==> trn\n",
    "            # i = 5 ==> trn\n",
    "            # i = 6 ==> dev \n",
    "            # ...\n",
    "            f_uris = uris_trn if i % 3 else uris_dev\n",
    "            f_uris.write(f'dev/{uri}\\n')\n",
    "            \n",
    "            # dump domain to disk\n",
    "            f_domain = domain_trn if i % 3 else domain_dev\n",
    "            f_domain.write(f'dev/{uri} {domain}\\n')\n",
    "            \n",
    "            # load and crop reference (cf above hack)\n",
    "            reference = load_rttm(f'{ldc2019e31}/data/single_channel/rttm/{uri}.rttm')[uri]\n",
    "            reference.uri = f'dev/{uri}'\n",
    "            reference = reference.crop(support, mode='intersection')\n",
    "            \n",
    "            # dump reference to disk\n",
    "            f_rttm = rttm_trn if i % 3 else rttm_dev\n",
    "            write_rttm(f_rttm, reference)\n",
    "            \n",
    "            # load and crop unpartitioned evaluation map\n",
    "            uem = uems[uri]\n",
    "            uem.uri = f'dev/{uri}'\n",
    "            uem = uem.crop(support, mode='intersection')\n",
    "            \n",
    "            # dump uem to disk\n",
    "            f_uem = uem_trn if i % 3 else uem_dev\n",
    "            write_uem(f_uem, uem)\n",
    "\n",
    "# same as above but applied to ldc2019e32 that is used entirely for test\n",
    "for domain, files in tst.groupby('domain'):\n",
    "    \n",
    "    uems = load_uem(f'{ldc2019e32}/data/single_channel/uem/{domain}.uem')\n",
    "\n",
    "    with open(f'{ROOT}/database/{domain}.tst.txt', 'w') as f_uris, \\\n",
    "         open(f'{ROOT}/database/{domain}.tst.rttm', 'w') as f_rttm, \\\n",
    "         open(f'{ROOT}/database/{domain}.tst.uem', 'w') as f_uem, \\\n",
    "         open(f'{ROOT}/database/{domain}.domain.tst.txt', 'w') as f_domain:\n",
    "\n",
    "        for i, (uri, file) in enumerate(files.iterrows()):\n",
    "            \n",
    "            duration = get_audio_duration({'audio': f'{ROOT}/database/tst/{uri}.flac'})\n",
    "            duration -= 0.001\n",
    "            support = Segment(0, duration)\n",
    "            \n",
    "            f_uris.write(f'tst/{uri}\\n')\n",
    "            \n",
    "            f_domain.write(f'tst/{uri} {domain}\\n')\n",
    "            \n",
    "            reference = load_rttm(f'{ldc2019e32}/data/single_channel/rttm/{uri}.rttm')[uri]\n",
    "            reference.uri = f'tst/{uri}'\n",
    "            reference = reference.crop(support, mode='intersection')\n",
    "\n",
    "            write_rttm(f_rttm, reference)\n",
    "            \n",
    "            uem = uems[uri]\n",
    "            uem.uri = f'tst/{uri}'\n",
    "            uem = uem.crop(support, mode='intersection')\n",
    "\n",
    "            write_uem(f_uem, uem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `database.yml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "database_yml = {\n",
    "    'Databases': {\n",
    "        'DIHARD': f'{ROOT}/database/{{uri}}.flac',\n",
    "        'MUSAN': f'{musan}/{{uri}}.wav',\n",
    "        'AMI': f'TODO/{{uri}}.wav',\n",
    "    },\n",
    "    'Protocols': {\n",
    "        'DIHARD': {'SpeakerDiarization': {}},\n",
    "        'AMI': {'SpeakerDiarization': 'TODO'},\n",
    "        'X': {'SpeakerDiarization': {}}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for domain in domains:\n",
    "    database_yml['Protocols']['DIHARD']['SpeakerDiarization'][f'{domain}'] = {}\n",
    "    for subset, short in {'train': 'trn', 'development': 'dev', 'test': 'tst'}.items():\n",
    "        database_yml['Protocols']['DIHARD']['SpeakerDiarization'][f'{domain}'][subset] = {\n",
    "            'uris': f'{ROOT}/database/{domain}.{short}.txt',\n",
    "            'annotation': f'{ROOT}/database/{domain}.{short}.rttm',\n",
    "            'annotated': f'{ROOT}/database/{domain}.{short}.uem',\n",
    "            'domain': f'{ROOT}/database/{domain}.domain.{short}.txt',\n",
    "        }\n",
    "    \n",
    "    all_but_domain = sorted(set(domains) - {domain})\n",
    "    database_yml['Protocols']['X']['SpeakerDiarization'][f'DIHARD_LeaveOneDomainOut_{domain}'] = {}\n",
    "    for subset in ['train', 'development']:\n",
    "        database_yml['Protocols']['X']['SpeakerDiarization'][f'DIHARD_LeaveOneDomainOut_{domain}'][subset] = {\n",
    "            f'DIHARD.SpeakerDiarization.{other_domain}': [subset] for other_domain in all_but_domain\n",
    "        }\n",
    "    database_yml['Protocols']['X']['SpeakerDiarization'][f'DIHARD_LeaveOneDomainOut_{domain}']['test'] = {\n",
    "        f'DIHARD.SpeakerDiarization.{domain}': ['test']\n",
    "    }   \n",
    "    \n",
    "database_yml['Protocols']['X']['SpeakerDiarization']['DIHARD_Official'] = {\n",
    "    subset: {\n",
    "        f'DIHARD.SpeakerDiarization.{domain}': [subset] for domain in domains\n",
    "    } for subset in ['train', 'development', 'test']\n",
    "}\n",
    "\n",
    "with open(f'{ROOT}/database.yml', 'w') as f:\n",
    "    f.write(yaml.dump(database_yml, \n",
    "                      default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `PYANNOTE_DATABASE_CONFIG` environment variable to `{ROOT}/database.yml` will give you a bunch of `pyannote.database` protocols:\n",
    "\n",
    "- `X.SpeakerDiarization.DIHARD_Official` is the official protocol for `DIHARD2` \n",
    "- `X.SpeakerDiarization.DIHARD_LeaveOneDomainOut_{domain}` uses all domains but {domain} in the training and development sets, and only {domain} in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
